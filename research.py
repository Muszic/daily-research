import os
import random
import re
import requests
import io
import urllib.request
import xml.etree.ElementTree as ET
from datetime import datetime
import google.generativeai as genai
from pypdf import PdfReader

# --- CONFIGURATION ---
CATEGORIES = ['cs.CV', 'cs.AI', 'cs.LG', 'cs.CL', 'cs.RO']
CATEGORY_NAMES = {
    'cs.CV': 'Computer Vision',
    'cs.AI': 'Artificial Intelligence',
    'cs.LG': 'Machine Learning',
    'cs.CL': 'NLP',
    'cs.RO': 'Robotics'
}

# Configure Gemini
GENAI_KEY = os.environ.get("GEMINI_API_KEY")
if GENAI_KEY:
    genai.configure(api_key=GENAI_KEY)
else:
    print("WARNING: No API Key found. Summary will be skipped.")

def fetch_random_paper():
    selected_category = random.choice(CATEGORIES)
    print(f"Selected Category: {selected_category}")
    
    url = f'http://export.arxiv.org/api/query?search_query=cat:{selected_category}&start=0&max_results=30&sortBy=submittedDate&sortOrder=descending'
    
    try:
        with urllib.request.urlopen(url) as response:
            data = response.read()
        
        root = ET.fromstring(data)
        entries = root.findall('{http://www.w3.org/2005/Atom}entry')
        if not entries: return None

        random_entry = random.choice(entries)
        
        # Get the PDF link (replace 'abs' with 'pdf')
        pdf_link = random_entry.find('{http://www.w3.org/2005/Atom}id').text.replace("/abs/", "/pdf/") + ".pdf"
        
        return {
            "title": random_entry.find('{http://www.w3.org/2005/Atom}title').text.replace('\n', ' ').strip(),
            "date": random_entry.find('{http://www.w3.org/2005/Atom}published').text[:10],
            "link": random_entry.find('{http://www.w3.org/2005/Atom}id').text,
            "pdf_link": pdf_link,
            "category": CATEGORY_NAMES.get(selected_category, selected_category)
        }
    except Exception as e:
        print(f"Error fetching metadata: {e}")
        return None

def extract_text_from_pdf(pdf_url):
    print(f"Downloading PDF: {pdf_url}...")
    try:
        response = requests.get(pdf_url)
        f = io.BytesIO(response.content)
        reader = PdfReader(f)
        
        text = ""
        # Only read the first 5 pages to save time/tokens (usually enough for Intro/Results)
        for page in reader.pages[:5]: 
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        print(f"Error reading PDF: {e}")
        return None

def generate_ai_summary(text):
    if not GENAI_KEY: return "API Key missing. Could not generate summary."
    
    print("Sending text to Gemini for analysis...")
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    prompt = """
    You are an expert research assistant. Read the following academic paper text and generate a structured summary.
    
    The Output format must be in Markdown:
    ## üßê Problem Statement
    (What problem is this paper trying to solve?)
    
    ## üõ†Ô∏è Methodology
    (How did they solve it? What models or algorithms did they use?)
    
    ## üìä Results & Impact
    (What were the key findings? Did they beat state-of-the-art?)
    
    Here is the paper text:
    """ + text[:30000] # Truncate to ensure we don't hit limits
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Gemini Error: {e}")
        return "AI generation failed."

def save_paper_note(paper, ai_summary):
    if not os.path.exists("papers"):
        os.makedirs("papers")

    safe_title = re.sub(r'[^\w\-_\. ]', '', paper['title']).replace(' ', '_')[:40]
    filename = f"papers/{paper['date']}_{safe_title}.md"
    
    if os.path.exists(filename):
        print("File already exists. Skipping.")
        return

    content = f"""# {paper['title']}

- **Category:** {paper['category']}
- **Published:** {paper['date']}
- **Source:** [Original ArXiv Link]({paper['link']})

---

{ai_summary}

---
*Generated by Gemini 1.5 Flash via ArXiv API*
"""
    
    with open(filename, "w", encoding='utf-8') as f:
        f.write(content)
    print(f"Saved: {filename}")

if __name__ == "__main__":
    paper = fetch_random_paper()
    if paper:
        # 1. Download & Extract Text
        pdf_text = extract_text_from_pdf(paper['pdf_link'])
        
        if pdf_text:
            # 2. Generate Summary
            summary = generate_ai_summary(pdf_text)
            
            # 3. Save File
            save_paper_note(paper, summary)
