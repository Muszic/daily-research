# MUSE: Harnessing Precise and Diverse Semantics for Few-Shot Whole Slide Image Classification

- **Category:** Computer Vision
- **Date:** 2026-02-24
- **Link:** http://arxiv.org/abs/2602.20873v1

---
```markdown
### Problem

Few-shot Whole Slide Image (WSI) classification is severely limited by the extreme scarcity of expert-labeled slides in computational pathology. Existing vision-language (VL) methods, while incorporating textual semantics generated by Large Language Models (LLMs), treat these descriptions as static, class-level priors. This approach has two key limitations:
*   **Lack of Sample-wise Refinement:** Semantics are shared across all samples, preventing fine-grained disentanglement of diagnostic attributes relevant to individual WSIs. This leads to coarse visual-semantic alignment that fails to attend to diagnostically relevant regions with concept-level precision.
*   **Limited Semantic Diversity:** Reliance on unoptimized prompts ignores the rich structural and perspectival diversity of clinical language. This underutilizes the text encoder's expressive capacity and encourages overfitting to specific phrasings, hindering generalization in low-data regimes.

### Method

The authors propose **MUSE (Stochastic MUlti-view Semantic Enhancement)**, a framework designed to jointly enhance precise semantic perception and enriched semantic diversity for few-shot WSI classification. MUSE comprises two core components:

1.  **Sample-wise Fine-grained Semantic Enhancement (SFSE):**
    *   **Goal:** Refine semantic precision by adapting class-level semantics to individual samples.
    *   **Process:**
        *   **Decompositional Semantic Refinement (DSR):** Decomposes generic class-level textual prompts (augmented with learnable vectors) into multiple fine-grained, task-relevant *semantic cues* using a Mixture-of-Experts (MoE) paradigm.
        *   **Sample-wise Visionâ€“Text Interaction (SVTI):** Utilizes multi-head cross-attention where these fine-grained semantic cues query visual patch features extracted from the WSI. It selectively aggregates the most semantically relevant visual features, generating a **fine-grained, sample-level semantic prior** for each WSI. This prior reflects sub-concepts visually supported by the current sample.

2.  **Stochastic Multi-view Model Optimization (SMMO):**
    *   **Goal:** Enhance semantic richness and promote generalization through diverse textual views.
    *   **Process:**
        *   **LLM-based Semantic Knowledge Base Generation:** An offline process leveraging GPT-4 and a locally deployed LLM (Qwen-7B). GPT-4 first decomposes class names into four visual diagnostic aspects (e.g., cellular morphology, tissue architecture) and generates exemplar descriptions. These exemplars guide the local LLM to generate 300 *diverse, multi-view textual descriptions* per category, forming a comprehensive knowledge base.
        *   **LLM-based Multi-view Semantic Retrieval:** The sample-level semantic prior from SFSE (after an adapter) is used to query the generated knowledge base via cosine similarity, retrieving a set of top-`m` semantically relevant texts for the current sample's ground-truth class.
        *   **Stochastic Optimization with Multiple-Semantics:** During training, a single text description is stochastically dequeued from the retrieved set. This text is processed through DSR and SVTI to create an *auxiliary sample-wise prior*. This auxiliary prior is then fused with the primary sample prior to generate the final prediction logits. The model is optimized using cross-entropy loss, which exposes it to a dynamically varying set of semantic supervisions, enhancing robustness and mitigating overfitting.

### Impact

MUSE consistently achieves **state-of-the-art performance** in few-shot WSI classification across three benchmark datasets: CAMELYON, TCGA-NSCLC, and TCGA-BRCA.
*   **Superior Performance:** It significantly outperforms existing traditional MIL and VLM-based baselines, particularly in extreme few-shot settings (e.g., 4-shot, 8-shot). For instance, in the 4-shot setting, MUSE improved ACC by 6.73% on CAMELYON, 0.76% on TCGA-NSCLC, and 2.34% on TCGA-BRCA over the best baseline.
*   **Enhanced Generalization:** By actively and sample-awarely optimizing diverse and precise semantic information, MUSE effectively mitigates the scarcity of visual supervision, leading to improved generalization capability.
*   **Novelty:** This work is the first to address few-shot WSI classification through the perspective of semantic optimization, demonstrating that both richer semantic sources and their dynamic, sample-aware utilization are crucial for effective learning in computational pathology.
*   **Robustness:** The stochastic integration of multi-view semantics promotes model robustness and helps mitigate overfitting inherent in low-data scenarios.
```