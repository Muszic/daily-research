# LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals

- **Category:** NLP
- **Date:** 2026-01-15
- **Link:** http://arxiv.org/abs/2601.10700v1

---
This paper introduces LIBERTy, a novel framework for benchmarking concept-based explanations of Large Language Models (LLMs) using structural counterfactuals.

### Problem

Evaluating the faithfulness of concept-based explanations, which quantify the influence of high-level concepts (e.g., gender, experience) on model behavior, is crucial for decision-makers in high-stakes domains. Existing benchmarks, such as CEBaB, rely on human-written counterfactuals to estimate reference causal effects. This approach is problematic because:
1.  **Costly and Imperfect:** Human-written counterfactuals are expensive to generate and serve as an imperfect proxy for true causal effects, as they don't arise from the actual data-generating process (DGP).
2.  **Limited Scope:** Existing benchmarks are typically confined to simple texts (e.g., sentiment analysis of short restaurant reviews) and feature overly simplistic causal graphs (e.g., only four concepts with basic relationships), failing to capture the structural complexity of real-world data.
3.  **Inaccessibility of Ground Truth:** The true underlying causal mechanisms that generate data are generally inaccessible, making it difficult to reliably assess whether an explanation is truly faithful.

### Method

LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets) addresses these limitations by providing a framework for constructing interventional datasets with gold-standard structural counterfactual pairs.

1.  **Structural Causal Models (SCMs):** The core of LIBERTy is explicitly defining an SCM for the text generation process. This SCM specifies concepts as variables and their causal relationships as a directed acyclic graph. Each concept's value is determined by its parent concepts and an exogenous noise term.
2.  **LLM as a Component:** An LLM (specifically GPT-4o with deterministic decoding, temperature=0) is integrated into the SCM to instantiate concepts as natural language text. It receives concept values, persona, and template as input.
3.  **Exogenous Grounding Texts:** To overcome the limitations of deterministic decoding (which can produce generic and repetitive texts), LIBERTy introduces two additional exogenous variables:
    *   `Persona`: contextual attributes (profession, hobbies, motivations).
    *   `Template`: a discourse structure derived from real-world corpora (e.g., personal statements, Reddit posts).
    These grounding texts promote diversity, ensure generated texts resemble authentic human writing, and maintain consistent narratives between factual and counterfactual examples.
4.  **Structural Counterfactual Generation:** Counterfactuals are generated by applying Pearl's three-step procedure:
    *   **Abduction:** Fix all exogenous variables (including persona, template, and Gaussian noise).
    *   **Action:** Intervene on a target concept by assigning it a new value.
    *   **Prediction:** Propagate this intervention through the SCM, culminating in the LLM generating the corresponding counterfactual text with all other exogenous variables held fixed. This ensures the counterfactuals are "silver" ground truth with respect to the synthetic DGP.
5.  **New Datasets:** LIBERTy introduces three complex interventional datasets, each grounded in major societal challenges and featuring richer causal graphs (at least eight concepts, with confounding and mediation structures, longer paths) than previous benchmarks:
    *   Disease Detection
    *   CV Screening
    *   Workplace Violence Prediction
6.  **New Evaluation Metric:** Besides traditional error distance metrics (cosine, L2, norm difference), the paper introduces **Order-Faithfulness**. This metric quantifies how well an explanation method captures the relative ordering of effects induced by different concept interventions, assessing whether explanations preserve the correct "greater than" or "less than" relationships between concept importances.

### Impact

LIBERTy makes several significant contributions and findings:

1.  **Reliable and Scalable Benchmark:** It provides a much-needed, reliable, scalable, and flexible causal framework for generating benchmarks, eliminating the dependency on costly and imperfect human annotations for ground-truth causal effects.
2.  **Identified Headroom for Improvement:** Extensive experiments across five NLP models and LLMs, evaluating a wide range of concept-based explanation methods (e.g., linear erasure, counterfactual generation, matching, attributions), reveal substantial headroom for improving the faithfulness of current concept-based explanation methods. Matching methods based on fine-tuned model representations generally performed best.
3.  **Systematic Analysis of Model Sensitivity:** LIBERTy enables systematic analysis of how models respond to concept interventions. For instance, it found that fine-tuned models can track the ground-truth causal effects specified in the SCM. In contrast, proprietary LLMs like GPT-4o exhibited markedly reduced sensitivity to demographic concepts, suggesting the impact of dedicated post-training alignment or mitigation strategies.
4.  **Advancement in Explainability Evaluation:** By offering structural counterfactuals and the novel Order-Faithfulness metric, LIBERTy significantly advances the methodology for rigorously evaluating concept-based explanations, moving towards assessing true causal reasoning rather than indirect proxies.
5.  **Foundation for Future Research:** The framework and datasets pave the way for developing more faithful and robust explainability methods, especially for LLMs operating in high-stakes domains.